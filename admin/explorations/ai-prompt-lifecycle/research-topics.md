# Research Topics - AI Prompt Lifecycle

**Status:** ðŸ”´ Scaffolding (needs expansion)
**Created:** 2026-02-20

---

## ðŸ“‹ Topics Identified

### Topic 1: LLM API Anatomy and Context Windows

**Question:** What is the complete structure of an LLM API call, and how do context windows, token limits, and message roles work?
**Priority:** High

### Topic 2: Cursor IDE Prompt Assembly

**Question:** How does Cursor assemble the full prompt when a user invokes a command, and how are rules, commands, open files, and conversation history prioritized?
**Priority:** High

### Topic 3: Command File Effectiveness at Scale

**Question:** Are long command files (500-1000+ lines) fully consumed by the model, or is there diminishing returns or truncation at certain sizes?
**Priority:** High

### Topic 4: Claude Code Instruction Architecture

**Question:** How does Claude Code's CLAUDE.md and skills system work mechanically, and how does it compare to Cursor's rules/commands injection?
**Priority:** Medium

### Topic 5: AI Coding Tool Instruction Patterns

**Question:** What patterns do other AI coding tools (Aider, Continue.dev, Windsurf, Copilot) use for structured instructions, and are there emerging standards?
**Priority:** Medium

---

## ðŸš€ Next Steps

Run `/explore ai-prompt-lifecycle --conduct` to expand these topics with context and rationale.
